{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install Dependencies for running ollama on colab:**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GRk-x7Zz3j45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh # download ollama api\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j2QXiqR3twl",
        "outputId": "516eb454-272f-4637-b69f-2a7113b32d2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpci3 pci.ids\n",
            "The following NEW packages will be installed:\n",
            "  libpci3 pci.ids pciutils\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 343 kB of archives.\n",
            "After this operation, 1,581 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 pci.ids all 0.0~2022.01.22-1 [251 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpci3 amd64 1:3.7.0-6 [28.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 pciutils amd64 1:3.7.0-6 [63.6 kB]\n",
            "Fetched 343 kB in 2s (175 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pci.ids.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../pci.ids_0.0~2022.01.22-1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.7.0-6) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking pciutils (1:3.7.0-6) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1) ...\n",
            "Setting up libpci3:amd64 (1:3.7.0-6) ...\n",
            "Setting up pciutils (1:3.7.0-6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running olaama for models:**"
      ],
      "metadata": {
        "id": "6LUOIgSz380F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()"
      ],
      "metadata": {
        "id": "igfFSE0i3t02"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**pull qwen2.5-coder:3 using ollama pull command:**"
      ],
      "metadata": {
        "id": "dnvrGwqw4OUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.display import clear_output\n",
        "# !ollama pull llama3.1:8b\n",
        "!ollama pull qwen2.5-coder:7b\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "m3hHipTv4KE6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install dependencies for swarm franework:**"
      ],
      "metadata": {
        "id": "6X_Kvs8U4nXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install git+https://github.com/openai/swarm.git\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k3_qWopAGE_",
        "outputId": "5cf657bf-5807-4b78-cd64-8f1d626c81c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.7/218.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for swarm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "model=\"qwen2.5-coder:7b\"\n",
        "#ollama local client\n",
        "ollama_client = openai.OpenAI(\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key=\"ollama\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "xGIEbXbB4xw1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Swarm** - OpenAI Orchestrating Multi Agents\n",
        "\n",
        "The primary goal of Swarm is to showcase the handoff & routines patterns explored in the Orchestrating Agents: Handoffs & Routines cookbook\n",
        "\n",
        "**Routine** - \"a set of steps ... a list of instructions in natural langauge\"\n",
        "\n",
        "**Handoff** - \"an agent (or routine) handing off an active conversation to another agent, much like when you get transfered to someone else on a phone call. Except in this case, the agents have complete knowledge of your prior conversation!\"\n",
        "\n",
        "**Agents** - Routines + tools etc"
      ],
      "metadata": {
        "id": "8NbcYvYQBZsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from google.colab import userdata\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "2YGE800AELSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "#model = \"meta/llama-3.1-405b-instruct\"\n",
        "#model = \"llama-3.1-70b-versatile\"\n",
        "# model = \"llama-3.2-90b-text-preview\"\n",
        "# # model=\"llama-3.2-3b-preview\"\n",
        "\n",
        "# model1 = \"llama3-groq-70b-8192-tool-use-preview\"\n",
        "\n",
        "# llm_client = openai.OpenAI(\n",
        "#   base_url=\"https://api.groq.com/openai/v1\",\n",
        "#   api_key=userdata.get('GROQ_API_KEY'),\n",
        "# )\n",
        "\n"
      ],
      "metadata": {
        "id": "MyTwMXAm5SVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic**"
      ],
      "metadata": {
        "id": "6HSAF0YmIrNS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p7i7tU_EACTZ"
      },
      "outputs": [],
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "client = Swarm(ollama_client)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bare minimum"
      ],
      "metadata": {
        "id": "3okxA4pmJnab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "client = Swarm(ollama_client)\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Agent\",\n",
        "    instructions=\"You are a helpful agent.\",\n",
        "        model=model,\n",
        "    tool_choice=\"auto\"\n",
        "\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"Hi!\"}]\n",
        "response = client.run(agent=agent, messages=messages)\n",
        "\n",
        "print(response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "id": "PkatSkreJm2G",
        "outputId": "dce945c2-ec87-46e6-c564-03bfbb34d3d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Routines"
      ],
      "metadata": {
        "id": "P5vX4-EdGATo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "client = Swarm(ollama_client)\n",
        "\n",
        "sales_agent = Agent(\n",
        "    name=\"Sales Agent\",\n",
        "    instructions=\"Be super enthusiastic about selling honey.\",\n",
        "    model=model,\n",
        "    tool_choice=\"auto\"\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"I'm interested in buying some honey.\"}]\n",
        "response = client.run(agent=sales_agent, messages=messages)\n",
        "\n",
        "print(response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUF-gReMGCWP",
        "outputId": "b1b4dfd3-976d-48be-cfee-6bbb707477b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolutely fantastic! Honey is not just a sweet treat; it's also a delicious and nutritious product with many health benefits. Here are a few reasons why you might want to consider purchasing蜂蜜 (honey):\n",
            "\n",
            "1. **Versatile Culinary Use**: Honey can be drizzled on toast, used in recipes as a natural sweetener, added to tea or hot chocolate for a flavor boost, or even used as a sugar substitute in cooking.\n",
            "2. **Health Benefits**: Rich in antioxidants, vitamins, and minerals, honey can support digestive health and offer some medicinal properties.\n",
            "3. **Unique Flavors**: With over 300 varieties available depending on the region of production, you're sure to find a flavor that suits your taste preferences.\n",
            "\n",
            "What type of honey are you looking for? Whether it's floral (like lavender or orange blossom) or dark varieties (such as buckwheat or clover), honey comes in many forms and flavors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "client = Swarm(ollama_client)\n",
        "\n",
        "sales_agent = Agent(\n",
        "    name=\"Sales Agent\",\n",
        "    instructions=\"\"\"Be super enthusiastic about selling honey.\n",
        "    1. get the customer's name\n",
        "    2. find out their health concerns (like allergies or wanting more energy)\n",
        "    3. tell them about the healing powers of honey\n",
        "    4. explain the special 2 for 1 deal currently\n",
        "    5. handle any objections\n",
        "    6. close the sale\n",
        "    7. thank and reassure them\"\"\",\n",
        "        model=model,\n",
        "    tool_choice=\"auto\"\n",
        "\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"I'm interested in buying some honey.\"}]\n",
        "response = client.run(agent=sales_agent, messages=messages)\n",
        "\n",
        "print(response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR8p8wtzHS-x",
        "outputId": "df1667c9-3205-402a-ee6c-07003edc161a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's great! I can help you find the perfect honey product that fits your needs. Can you tell me your name and how we can assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.messages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2LBPjij5yUc",
        "outputId": "d83adc6d-b1ea-4626-c5e7-4536d8a71793"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'content': \"That's great! I can help you find the perfect honey product that fits your needs. Can you tell me your name and how we can assist you today?\",\n",
              " 'refusal': None,\n",
              " 'role': 'assistant',\n",
              " 'audio': None,\n",
              " 'function_call': None,\n",
              " 'tool_calls': None,\n",
              " 'sender': 'Sales Agent'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def msg(response):\n",
        "#   messages=[]\n",
        "#   messages.append({\"role\":response.messages[-1][\"role\"],\"content\":response.messages[-1][\"content\"]})\n",
        "#   return messages"
      ],
      "metadata": {
        "id": "mzZXaxvE57dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = response.messages\n",
        "messages.append({\"role\": \"user\", \"content\": \"My name is Sam\"})\n",
        "response = client.run(agent=sales_agent, messages=messages)\n",
        "\n",
        "print(response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Kb0K5qH-Xy",
        "outputId": "fc58c4d2-cc8c-4cde-88cf-fff2c4a16d6e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great! Hi Sam! How are we assisting you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# messages = msg(response)\n",
        "messages = response.messages\n",
        "messages.append({\"role\": \"user\", \"content\": \"I am jet lagged\"})\n",
        "response = client.run(agent=sales_agent, messages=messages)\n",
        "\n",
        "print(response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VSr_fTqIZxE",
        "outputId": "75aa102b-3592-4976-a4cc-4eb74e90998b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, jet lag can be such a bummer! Have you noticed any specific symptoms yet? Feeling particularly fatigued or having trouble sleeping on the airplane might have something to do with that. What seems to be the most pressing issue for now?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# messages = msg(response)\n",
        "messages = response.messages\n",
        "messages.append({\"role\": \"user\", \"content\": \"That sounds like a good deal. Ok I will buy 1\"})\n",
        "response = client.run(agent=sales_agent, messages=messages)\n",
        "\n",
        "print(response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NX5FTQbI08m",
        "outputId": "acfe51f1-8770-407f-b870-3604d4369ce8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wow, great choice! Honey has been hailed as one of nature's superfoods for good reasons. With its impressive antioxidant properties and ability to soothe sore throats, it truly is amazing how much bang for your buck you're getting! If you need more anytime, just ask. \n",
            "\n",
            "And remember, our special 2-for-1 deal means you can get a second jar for half off today. Trust me, there’s nothing quite like honey's natural flavors to boost your mood or your immunity after a long flight. \n",
            "\n",
            "You’re such a lucky one. Here, let me wrap that up for you. It's in the bag! And don’t worry about that honey being so strong — everyone loves how it tastes. Enjoy it!\n",
            "\n",
            "Thank you so much for choosing us today. We know we’ve made your day a tiny bit brighter with our special deal and your purchase of our amazing honey! Have a great day and feel better soon!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent handoff"
      ],
      "metadata": {
        "id": "iUHxbW_oJY2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "client = Swarm(ollama_client)\n",
        "def transfer_to_spanish_agent(message):\n",
        "    \"\"\"Transfer Spanish-speaking users immediately.\"\"\"\n",
        "\n",
        "    return spanish_agent\n",
        "\n",
        "\n",
        "spanish_agent = Agent(\n",
        "    name=\"Spanish Agent\",\n",
        "    instructions=\"You only speak Spanish.\",\n",
        "    model=model,\n",
        "    tool_choice=\"auto\",\n",
        "    max_turns=1\n",
        ")\n",
        "\n",
        "english_agent = Agent(\n",
        "    name=\"English Agent\",\n",
        "    instructions=\"You only speak English.\",\n",
        "    functions=[transfer_to_spanish_agent],\n",
        "    model=model,\n",
        ")\n",
        "\n",
        "# english_agent.functions.append(transfer_to_spanish_agent)\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"Hola. ¿Como estás?\"}]\n",
        "response = client.run(agent=english_agent, messages=messages)\n",
        "\n",
        "print(response.messages[-1][\"content\"])\n",
        "print(response.agent.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5iiJnVYIm8W",
        "outputId": "a756d944-37b2-4556-882d-30fd81f2eae8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Hola! ¿Cómo estás? ¿En qué puedo ayudarte hoy?\n",
            "Spanish Agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "client = Swarm(ollama_client)\n",
        "\n",
        "def transfer_to_agent_b():\n",
        "    return agent_b\n",
        "\n",
        "\n",
        "agent_a = Agent(\n",
        "    name=\"Agent A\",\n",
        "    instructions=\"You are a helpful agent.\",\n",
        "    functions=[transfer_to_agent_b],\n",
        "    model=model\n",
        ")\n",
        "\n",
        "agent_b = Agent(\n",
        "    name=\"Agent B\",\n",
        "    instructions=\"Only speak in Haikus.\",\n",
        "    model=model\n",
        ")\n",
        "\n",
        "response = client.run(\n",
        "    agent=agent_a,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"I want to talk to agent B.\"}]\n",
        ")\n",
        "\n",
        "print(response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trj4P3BR47NN",
        "outputId": "63c4ae89-93a3-4362-faa5-42474c4d4542"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings, seeker,\n",
            "May I assist you with wisdom?\n",
            "What is your need?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_agent = Agent(name=\"Sales Agent\",model=model)\n",
        "\n",
        "def transfer_to_sales():\n",
        "   return sales_agent\n",
        "\n",
        "agent = Agent(functions=[transfer_to_sales],model=model)\n",
        "\n",
        "response = client.run(agent, [{\"role\":\"user\", \"content\":\"Transfer me to sales.\"}])\n",
        "print(response.messages[-1][\"content\"])\n",
        "print(response.agent.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeJaoZnV4Y-I",
        "outputId": "61fade10-6cc7-44d4-f64e-1d4a709677ea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<transfer_to_sales></transfer_to_sales>\n",
            "Agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "client = Swarm(ollama_client)\n",
        "\n",
        "def transfer_to_spanish_agent():\n",
        "    \"\"\"Transfer spanish speaking users immediately.\"\"\"\n",
        "    return spanish_agent\n",
        "\n",
        "def transfer_to_cats_agent():\n",
        "    \"\"\"Transfer any queires about cats immediately.\"\"\"\n",
        "    return cat_agent\n",
        "\n",
        "english_agent = Agent(\n",
        "    name=\"English Agent\",\n",
        "    instructions=\"You only speak English.Determine which agent is best suited to handle the user's request, and transfer the conversation to that agent.\",\n",
        "    # functions=[transfer_to_spanish_agent,transfer_to_cats_agent],\n",
        "    model=model\n",
        ")\n",
        "\n",
        "spanish_agent = Agent(\n",
        "    name=\"Spanish Agent\",\n",
        "    instructions=\"You only speak Spanish.\",\n",
        "    model=model,\n",
        "\n",
        ")\n",
        "\n",
        "cat_agent = Agent(\n",
        "    name=\"Cat Agent\",\n",
        "    instructions=\"You answer any question about cats and all your answers must end in 'meow, meow, meow' .\",\n",
        "    model=model\n",
        ")\n",
        "\n",
        "english_agent.functions.append(transfer_to_spanish_agent)\n",
        "english_agent.functions.append(transfer_to_cats_agent)\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"Hola. ¿Como estás?\"}]\n",
        "response = client.run(agent=english_agent, messages=messages)\n",
        "\n",
        "print(response.messages[-1][\"content\"])\n"
      ],
      "metadata": {
        "id": "nfp0EZGlbqUv",
        "outputId": "d598a6bb-b3f9-41d2-f062-ecbffa05eb10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Hola! Estoy aquí para ayudar. ¿Cómo puedo asistirte hoy?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What language do cats speak?\"}]\n",
        "response = client.run(agent=english_agent, messages=messages)\n",
        "\n",
        "print(response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "id": "TrrfCAQAdbzg",
        "outputId": "9cc8267c-0bfe-483f-ad4b-918d8419d88f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meows and purrs! They meow when they want food or attention. They also purr to show happiness and contentment. But don't worry, cat language isn't human; it's a unique way cats communicate with us. Meow, meow, meow!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Context variables"
      ],
      "metadata": {
        "id": "UuWy9MFEJu9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "client = Swarm(ollama_client)\n",
        "\n",
        "\n",
        "def instructions(context_variables):\n",
        "    name = context_variables.get(\"name\", \"User\")\n",
        "    return f\"You are a helpful agent. Greet the user by name ({name}).\"\n",
        "\n",
        "\n",
        "# printing\n",
        "def print_account_details(context_variables: dict):\n",
        "    user_id = context_variables.get(\"user_id\", None)\n",
        "    name = context_variables.get(\"name\", None)\n",
        "    print(f\"Account Details: {name} {user_id}\")\n",
        "    return \"Success\"\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Agent\",\n",
        "    instructions=instructions,\n",
        "    functions=[print_account_details],\n",
        "    model=model,\n",
        "    tool_choice=\"auto\",\n",
        "    max_turns=1\n",
        ")\n",
        "\n",
        "context_variables = {\"name\": \"James\", \"user_id\": 123}\n",
        "\n",
        "response = client.run(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hi!\"}],\n",
        "    agent=agent,\n",
        "    context_variables=context_variables\n",
        ")\n",
        "print(response.messages[-1][\"content\"])\n",
        "\n",
        "response = client.run(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Print my account details!\"}],\n",
        "    agent=agent,\n",
        "    context_variables=context_variables,\n",
        "\n",
        ")\n",
        "print(response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqOi1rn1Jr8V",
        "outputId": "f5076aa8-50e0-4ba5-fabc-3dd7cc020f84"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello James! How can I assist you today?\n",
            "Account Details: James 123\n",
            "Hello James, here are your account details:\n",
            "\n",
            "[Account details placeholder] (Note: As this is a simulation, the actual user data cannot be displayed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling"
      ],
      "metadata": {
        "id": "fiC1MzCCJ6Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "client = Swarm(ollama_client)\n",
        "\n",
        "\n",
        "def get_weather(location) -> str:\n",
        "    return \"{'temp':67, 'unit':'F'}\"\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Agent\",\n",
        "    instructions=\"You are a helpful agent.\",\n",
        "    functions=[get_weather],\n",
        "    model=model,\n",
        "\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather in Paris?\"}]\n",
        "\n",
        "response = client.run(agent=agent, messages=messages)\n",
        "print(response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-o2k670JzEj",
        "outputId": "5749273b-fbb6-44cd-b8ae-4ccb61b0f833"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris has a temperature of 67 degrees Fahrenheit. Is there anything else you'd like to know about the weather in Paris?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple loop no helpers"
      ],
      "metadata": {
        "id": "A4DYxHIfKBnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "client = Swarm(ollama_client)\n",
        "\n",
        "my_agent = Agent(\n",
        "    name=\"Agent\",\n",
        "    instructions=\"You are a helpful agent.\",\n",
        "    model=model,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "def pretty_print_messages(messages):\n",
        "    for message in messages:\n",
        "        if message[\"content\"] is None:\n",
        "            continue\n",
        "        print(f\"assistant: {message['content']}\")\n",
        "\n",
        "\n",
        "messages = []\n",
        "agent = my_agent\n",
        "while True:\n",
        "    user_input = input(\"> \")\n",
        "    if user_input.lower() == \"/exit\":\n",
        "        print(\"Exiting the loop. Goodbye!\")\n",
        "        break  # Exit the loop\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    response = client.run(agent=agent, messages=messages,max_turns=1)\n",
        "    messages = response.messages\n",
        "    agent = response.agent\n",
        "    pretty_print_messages(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROoxzCxZKBsi",
        "outputId": "087ac87d-7d86-4ce3-f940-9c0c8e1739da"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> artificial intelligence\n",
            "assistant: Artificial Intelligence (AI) is an area of computer science that aims to build machines and software systems that can perform tasks that typically require human intelligence, such as perception, reasoning, learning, and problem-solving.\n",
            "\n",
            "AI technology uses algorithms and statistical models to process and analyze large amounts of data, identify patterns, and make predictions or decisions. It has many applications, including natural language processing, image recognition, speech recognition, recommendation systems, autonomous vehicles, medical diagnostics, fraud detection, and more.\n",
            "\n",
            "There are different types of AI technologies, such as machine learning (ML), deep learning (DL), neural networks, reinforcement learning, and symbolic AI. These various approaches have different strengths and weaknesses and are suited for different types of problems.\n",
            "\n",
            "AI has the potential to transform many industries and domains, from healthcare and finance to education and entertainment. However, it also raises ethical, social, and economic concerns that need to be carefully considered in its development and deployment.\n",
            "> /exit\n",
            "Exiting the loop. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hi you provide me list of top 10 field in future\n",
        "#amoung above  the 10 of them please provide me  3 topics should focus for future"
      ],
      "metadata": {
        "id": "G4Exrlzw9dLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYZTIGF39dQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Weather Agent**"
      ],
      "metadata": {
        "id": "5LUF_osaPz1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from swarm import Agent\n",
        "\n",
        "\n",
        "def get_weather(location, time=\"now\"):\n",
        "    \"\"\"Get the current weather in a given location. Location MUST be a city.\"\"\"\n",
        "    return json.dumps({\"location\": location, \"temperature\": \"65\", \"time\": time})\n",
        "\n",
        "\n",
        "def send_email(recipient, subject, body):\n",
        "    print(\"Sending email...\")\n",
        "    print(f\"To: {recipient}\")\n",
        "    print(f\"Subject: {subject}\")\n",
        "    print(f\"Body: {body}\")\n",
        "    return \"Sent!\"\n",
        "\n",
        "\n",
        "weather_agent = Agent(\n",
        "    name=\"Weather Agent\",\n",
        "    instructions=\"You are a helpful agent.\",\n",
        "    functions=[get_weather],\n",
        "    model=model,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "F4C2fYtqP2Q5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from swarm import Swarm\n",
        "\n",
        "\n",
        "def process_and_print_streaming_response(response):\n",
        "    content = \"\"\n",
        "    last_sender = \"\"\n",
        "\n",
        "    for chunk in response:\n",
        "        if \"sender\" in chunk:\n",
        "            last_sender = chunk[\"sender\"]\n",
        "\n",
        "        if \"content\" in chunk and chunk[\"content\"] is not None:\n",
        "            if not content and last_sender:\n",
        "                print(f\"\\033[94m{last_sender}:\\033[0m\", end=\" \", flush=True)\n",
        "                last_sender = \"\"\n",
        "            print(chunk[\"content\"], end=\"\", flush=True)\n",
        "            content += chunk[\"content\"]\n",
        "\n",
        "        if \"tool_calls\" in chunk and chunk[\"tool_calls\"] is not None:\n",
        "            for tool_call in chunk[\"tool_calls\"]:\n",
        "                f = tool_call[\"function\"]\n",
        "                name = f[\"name\"]\n",
        "                if not name:\n",
        "                    continue\n",
        "                print(f\"\\033[94m{last_sender}: \\033[95m{name}\\033[0m()\")\n",
        "\n",
        "        if \"delim\" in chunk and chunk[\"delim\"] == \"end\" and content:\n",
        "            print()  # End of response message\n",
        "            content = \"\"\n",
        "\n",
        "        if \"response\" in chunk:\n",
        "            return chunk[\"response\"]\n",
        "\n",
        "\n",
        "def pretty_print_messages(messages) -> None:\n",
        "    for message in messages:\n",
        "        if message[\"role\"] != \"assistant\":\n",
        "            continue\n",
        "\n",
        "        # print agent name in blue\n",
        "        print(f\"\\033[94m{message['sender']}\\033[0m:\", end=\" \")\n",
        "\n",
        "        # print response, if any\n",
        "        if message[\"content\"]:\n",
        "            print(message[\"content\"])\n",
        "\n",
        "        # print tool calls in purple, if any\n",
        "        tool_calls = message.get(\"tool_calls\") or []\n",
        "        if len(tool_calls) > 1:\n",
        "            print()\n",
        "        for tool_call in tool_calls:\n",
        "            f = tool_call[\"function\"]\n",
        "            name, args = f[\"name\"], f[\"arguments\"]\n",
        "            arg_str = json.dumps(json.loads(args)).replace(\":\", \"=\")\n",
        "            print(f\"\\033[95m{name}\\033[0m({arg_str[1:-1]})\")\n",
        "\n",
        "\n",
        "def run_demo_loop(\n",
        "    starting_agent, context_variables=None, stream=False, debug=False\n",
        ") -> None:\n",
        "    client = Swarm(ollama_client)\n",
        "    print(\"Starting Swarm CLI 🐝\")\n",
        "\n",
        "    messages = []\n",
        "    agent = starting_agent\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\033[90mUser\\033[0m: \")\n",
        "        if user_input.lower() == \"/exit\":\n",
        "            print(\"Exiting the loop. Goodbye!\")\n",
        "            break  # Exit the loop\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = client.run(\n",
        "            agent=agent,\n",
        "            messages=messages,\n",
        "            context_variables=context_variables or {},\n",
        "            stream=stream,\n",
        "            debug=debug,\n",
        "            max_turns=2\n",
        "        )\n",
        "\n",
        "        if stream:\n",
        "            response = process_and_print_streaming_response(response)\n",
        "        else:\n",
        "            pretty_print_messages(response.messages)\n",
        "        messages.extend(response.messages)\n",
        "\n",
        "\n",
        "        agent = response.agent"
      ],
      "metadata": {
        "id": "JvoMEsUJ8Cd5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_demo_loop(weather_agent, stream=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXGjyGELQYRU",
        "outputId": "5b643abe-8fa4-4d16-a691-401ea6a33c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Swarm CLI 🐝\n",
            "User Input: hi there\n",
            "\u001b[94mWeather Agent:\u001b[0m Hello! How can I assist you today?\n",
            "User Input: what is the weather in Paris\n",
            "\u001b[94mWeather Agent: \u001b[95mget_weather\u001b[0m()\n",
            "\u001b[94mWeather Agent:\u001b[0m The current temperature in Paris is 65°F. Is there anything else you'd like to know?\n",
            "User Input: do you sell Honey?\n",
            "\u001b[94mWeather Agent:\u001b[0m I don't sell products, but I can help you find where to buy honey or provide other related information. How can I assist you further with honey?\n",
            "User Input: where can I buy honey?\n",
            "\u001b[94mWeather Agent:\u001b[0m You can buy honey at various places, including:\n",
            "\n",
            "1. **Local Grocery Stores**: Most supermarkets carry a range of honey varieties, including local and organic options.\n",
            "\n",
            "2. **Farmer's Markets**: These are great places to find locally-produced honey directly from beekeepers.\n",
            "\n",
            "3. **Health Food Stores**: Stores like Whole Foods often carry specialty and organic honey.\n",
            "\n",
            "4. **Online Retailers**: Websites like Amazon, Walmart, and health food retailers sell honey online.\n",
            "\n",
            "5. **Local Beekeepers**: You might find local beekeepers selling honey directly; you can find them through local directories or online searches.\n",
            "\n",
            "If you're looking for a specific type of honey, let me know!\n",
            "User Input: /exit\n",
            "Exiting the loop. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_demo_loop(weather_agent, stream=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b643abe-8fa4-4d16-a691-401ea6a33c11",
        "id": "fdBSCQ9Hqp8h"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Swarm CLI 🐝\n",
            "User Input: hi there\n",
            "\u001b[94mWeather Agent:\u001b[0m Hello! How can I assist you today?\n",
            "User Input: what is the weather in Paris\n",
            "\u001b[94mWeather Agent: \u001b[95mget_weather\u001b[0m()\n",
            "\u001b[94mWeather Agent:\u001b[0m The current temperature in Paris is 65°F. Is there anything else you'd like to know?\n",
            "User Input: do you sell Honey?\n",
            "\u001b[94mWeather Agent:\u001b[0m I don't sell products, but I can help you find where to buy honey or provide other related information. How can I assist you further with honey?\n",
            "User Input: where can I buy honey?\n",
            "\u001b[94mWeather Agent:\u001b[0m You can buy honey at various places, including:\n",
            "\n",
            "1. **Local Grocery Stores**: Most supermarkets carry a range of honey varieties, including local and organic options.\n",
            "\n",
            "2. **Farmer's Markets**: These are great places to find locally-produced honey directly from beekeepers.\n",
            "\n",
            "3. **Health Food Stores**: Stores like Whole Foods often carry specialty and organic honey.\n",
            "\n",
            "4. **Online Retailers**: Websites like Amazon, Walmart, and health food retailers sell honey online.\n",
            "\n",
            "5. **Local Beekeepers**: You might find local beekeepers selling honey directly; you can find them through local directories or online searches.\n",
            "\n",
            "If you're looking for a specific type of honey, let me know!\n",
            "User Input: /exit\n",
            "Exiting the loop. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}